{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishal/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import scipy.misc\n",
    "from scipy.stats import itemfreq\n",
    "from random import sample\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import PIL.Image\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:26<00:00, 386.50it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/vishal/dogbreed/train\"\n",
    "labels=pd.read_csv(\"/home/vishal/dogbreed/labels.csv\")\n",
    "train_dir = os.listdir( path )\n",
    "\n",
    "x_train=[]              #loading data and labels\n",
    "y_train=[]\n",
    "\n",
    "for img_name in tqdm(train_dir):\n",
    "    y_train.append((labels[labels[\"id\"]==img_name.split(\".\")[0]][\"breed\"].values[0]))  #Setting labels id = iamge name\n",
    "    x_train.append(cv2.resize((cv2.imread(path+\"/\"+img_name)),(97,97)).reshape(1,97,97,3)) #Reading and resizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.get_dummies(y_train).values  #Doing one hot encoding\n",
    "x_train=np.concatenate(x_train,axis=0)  #Stacking 10222 images in numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train,y_train, test_size=0.2, random_state=4) #Splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(x,y,start,batch_size):         #Defining a batch function for sending the images an labels array in batches \n",
    "    x_batch=x[start:start+batch_size]\n",
    "    y_batch=y[start:start+batch_size]\n",
    "    start=start+batch_size\n",
    "    return x_batch,y_batch,start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=.001\n",
    "batch_size=250\n",
    "n_epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,97,97,3],name=\"image\")   #Creating placeholders for x&y as well as initializing weights and biases\n",
    "x_image = tf.reshape(x, [-1,97,97,3])                      #Reshaping image size for conv1 layer input\n",
    "y=tf.placeholder(tf.float32,[None,120],name=\"labels\")\n",
    "w=tf.Variable(tf.random_normal(shape=[97*97*3,120]),name=\"weights\")\n",
    "b=tf.Variable(tf.zeros([1,120]),name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b2587c7b7811>:15: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CNN MODEL:\n",
    "conv1=tf.layers.conv2d(inputs=x_image,filters=32,kernel_size=[5,5],padding=\"SAME\",activation=tf.nn.relu)\n",
    "pool1=tf.layers.max_pooling2d(inputs=conv1, pool_size=[3, 3], strides=2)\n",
    "\n",
    "conv2=tf.layers.conv2d(inputs=pool1,filters=64,kernel_size=[5,5],padding=\"SAME\",activation=tf.nn.relu)\n",
    "pool2=tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "pool2_flat=tf.reshape(pool2,[-1,24*24*64])\n",
    "dense=tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "drop_layer=tf.nn.dropout(dense,keep_prob)\n",
    "\n",
    "logits = tf.layers.dense(inputs=drop_layer, units=120)\n",
    "entropy=tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "loss=tf.reduce_mean(entropy)\n",
    "optimizer=tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:24<04:48, 144.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 31, training accuracy 0.012000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [04:59<02:29, 149.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 31, training accuracy 0.012000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 3/3 [07:30<00:00, 150.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 31, training accuracy 0.008000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: test accuracy 0.008000\n",
      "avg test accuracy: 0.10000000474974513\n"
     ]
    }
   ],
   "source": [
    "test_size =8\n",
    "num_steps=32\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        start=0\n",
    "        for step in range(num_steps):\n",
    "            x_batch,y_batch,start= batch(x_train,y_train,start,batch_size)\n",
    "            if step % 10 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={\n",
    "                x:x_batch, y: y_batch, keep_prob: 1.0})\n",
    "            \n",
    "            optimizer.run(feed_dict={x: x_batch, y: y_batch, keep_prob: 0.5})\n",
    "        print('Epoch %d, step %d, training accuracy %f' %(epoch,step, train_accuracy))\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    start=0\n",
    "    for i in xrange(test_size):\n",
    "        x_batch,y_batch,start= batch(x_test,y_test,start,batch_size)\n",
    "        acc = accuracy.eval(feed_dict={x: x_batch, y:y_batch, keep_prob: 1.0})\n",
    "        if i % 10 == 0:\n",
    "            print('%d: test accuracy %f' % (i, acc))\n",
    "            test_accuracy += acc\n",
    "    print 'avg test accuracy:', 100*test_accuracy/(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
